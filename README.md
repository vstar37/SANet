<h1 align="center">Incremental Structural Adaptation for Camouflaged Object Detection</h1>

## üóûÔ∏è News
* **`Nov 21, 2024`:** First release.

## üí° Overview
This repository provides a PyTorch implementation of **SANet**, a **Structure-Adaptive Network** designed for **Camouflaged Object Detection** (COD).  
SANet addresses the challenges of detecting camouflaged objects by incorporating an innovative incremental structural adaptation mechanism, which enhances the model's ability to refine segmentation and improve localization in complex environments.  
The key feature of SANet is its ability to adaptively integrate high-resolution structural information, enabling fine-grained detection of camouflaged objects that closely resemble their backgrounds.

---

## üíª Environment

- **OS:** Ubuntu 20.04  
- **CUDA:** 11.8  
- **Python:** 3.10  
- **PyTorch:** 2.0.1 (tested)  
- Other required packages: see [`requirements.txt`](./requirements.txt)

---

## üí° Usage

### Installation
To use this repository, follow the steps below to set up the environment:

1. **Clone the repository:**
   ```bash
   git clone https://github.com/vstar37/SANet.git
   cd SANet

2.	**Install the required dependencies:**
    It is recommended to create a virtual environment first, then install the dependencies.
    ```bash
    # PyTorch==2.0.1 is used for faster training with compilation.
    conda create -n sanet python=3.10 -y && conda activate sanet
    pip install -r requirements.txt

3. **Download the datasets:**
   [Download datasets](https://drive.google.com/drive/folders/1ehBdZcQWRVshFxR2u7-E1Uv-fwhkdOiE?usp=drive_link)
    After setting up the environment, you can download the training and test datasets from the provided links. Once downloaded, please unzip the datasets into the data folder under the root directory of the project. The folder structure should look like this:
   ```bash
   SANet/
   ‚îú‚îÄ‚îÄ datasets/
   ‚îÇ   ‚îú‚îÄ‚îÄ CAMO_TestingDataset/
   ‚îÇ   ‚îú‚îÄ‚îÄ CHAMELEON_TestingDataset/
   ‚îÇ   ‚îú‚îÄ‚îÄ COD10K_TestingDataset/
   ‚îÇ   ‚îú‚îÄ‚îÄ NC4K_TestingDataset/
   ‚îÇ   ‚îî‚îÄ‚îÄ COD10K_CAMO_CHAMELEON_TrainingDataset/
   ‚îú‚îÄ‚îÄ requirements.txt
   ‚îî‚îÄ‚îÄ ‚Ä¶ (other project files)

### Run
```shell
# Train & Test & Evaluation
./sub.sh RUN_NAME GPU_NUMBERS_FOR_TRAINING GPU_NUMBERS_FOR_TEST
# Example: ./sub.sh  0,1,2,3,4,5,6,7 0

# See train.sh / test.sh for only training / test-evaluation.
# After the evaluation, run `gen_best_ep.py` to select the best ckpt from a specific metric (you choose it from Sm, wFm).
```


## üí° Results

### 1. Model Weight
| Name | Backbone | Params | Weight |
|  :---: |  :---:    | :---:   |  :---:   |
| SANet-S |  Swin-S    |  87.3   |  [[Geogle Drive](https://drive.google.com/drive/folders/1ehBdZcQWRVshFxR2u7-E1Uv-fwhkdOiE?usp=drive_link)]|
| SANet-L |  Swin-L    |  241.209  |  [[Geogle Drive](https://drive.google.com/drive/folders/1ehBdZcQWRVshFxR2u7-E1Uv-fwhkdOiE?usp=drive_link)]|

- **Model Weights:** The model weights should be placed in the `ckpt/COD` directory.
- **Backbone Weights:** The backbone weights should be placed in the `lib/weights/backbones` directory.
After downloading the datasets, you will need to download the pretrained weights for the model and the backbone. These weights are required to initialize the model for training and inference.

### 2. Prediction Maps
We offer the prediction maps of **SANet-S** [[baidu](https://pan.baidu.com/s/13MKOObYH6afYzF7P-2vjeQ),PIN:gsvf] and **SANet-L** [[Geogle Drive](https://drive.google.com/file/d/17q1poRj1FagWDoVSSX1712Wl9P32xRHO/view?usp=share_link)] at this time.

### 3. Polyp and SOD Prediction Maps
We offer the prediction maps of **SANet-L** [[Polyp](https://drive.google.com/file/d/1YGrEHNHIYh9Y9iSXR-8CB3fq5-OjYQbF/view?usp=share_link)], [[SOD](https://drive.google.com/file/d/1Nl2yjuWZb-cF5vWX8rREaeQ7RyvasWgk/view?usp=share_link)] at this time.




   
